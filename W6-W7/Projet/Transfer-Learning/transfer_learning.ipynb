{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c865afca",
   "metadata": {},
   "source": [
    "# **Détection de la pneumonie - Application du Transfer Learning**\n",
    "\n",
    "Dans ce notebook, nous nous attacherons à entraîner un modèle capable de détecter la pneumonie à partir d'images scanner. Pour ce faire nous utiliserons le dataset **[Chest XRay Pneumonia](https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia)** pour affiner un modèle Keras préentrainé. Nous suivrons ces étapes :  \n",
    "\n",
    "### **1. Compréhension du problème**  \n",
    "\n",
    "La 1ère étape est de comprendre notre problématique. Cela nous permettra d'en tirer certaines conclusions, telles que le choix de la métrique à laquelle nous accorderons le plus d'importance, ou la façon de résoudre les autres questions qui arriveront lors de la mise en oeuvre.  \n",
    "\n",
    "### **2. Analyse du dataset**  \n",
    "\n",
    "Nous devrons observer le dataset pour déterminer comment en standardiser le contenu afin de le rendre exploitable par le modèle.\n",
    "Nous devrons également prêter attention à la répartition des classes dans le dataset, afin de rééquilibrer l'entraînement si nécessaire.  \n",
    "\n",
    "### **3. Preprocessing du dataset**\n",
    "\n",
    "Nous adapterons notre dataset au format attendu par le modèle.\n",
    "\n",
    "### **4. Création du modèle**\n",
    "\n",
    "Le modèle sera créé par une fonction selon les paramètres définis dans settings.\n",
    "\n",
    "### **5. Entraînement du modèle**\n",
    "\n",
    "Nous entrainerons le modèle sur notre dataset d'entraînement, et surveillerons ses résultats à chaque epoch pour vérifier qu'il évolue dans le bon sens et ne se surentraîne pas.\n",
    "\n",
    "### **6. Mise en place d'un suivi des tests**  \n",
    "\n",
    "Grâce à MLFlow, nous enregistrerons les résultats de nos tests au fur et à mesure (paramètres et résultats) afin de facilement comparer nos modèles/paramètres d'entraïnement. Cela nous permetre de passer à l'étape suivante :  \n",
    "\n",
    "### **7. Choix du modèle**  \n",
    "\n",
    "Après avoir testé différents modèles préentrainés potentiellement intéressants, nous les comparerons grâce aux métriques enregistrés dans MLFlow afin de choisir notre modèle de travail final.  \n",
    "\n",
    "### **8. Affiner notre modèle**  \n",
    "\n",
    "Une fois notre modèle final sélectioné, nous jouerons avec ses paramètres afin de chercher les meilleures performances possibles pour le cas étudié.  \n",
    "\n",
    "### **9. Résultats finaux**  \n",
    "\n",
    "Nous présenterons les résultats finaux de notre modèle et le mettrons à disposition pour démonstration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53facc5a",
   "metadata": {},
   "source": [
    "## **0.a Importation des dépendances**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf8e106",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import kagglehub\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "from mlflow import MlflowClient\n",
    "from mlflow.models.signature import infer_signature\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from functions.data.prepare_data import prepare_data\n",
    "from functions.show_predictions import show_predictions\n",
    "from functions.data.get_train_test import get_train_test\n",
    "from functions.initialize_model import initialize_model\n",
    "from functions.mlflow.get_run_name import get_run_name\n",
    "from settings import params, model_name, folders, added_layers, experiment_name, testing_cycle\n",
    "from functions.mlflow.show_parameters import show_parameters\n",
    "from functions.data.dataset_analysis import dataset_analysis\n",
    "from functions.mlflow.show_metrics import show_metrics\n",
    "from functions.mlflow.show_matrix import show_matrix\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa01be03",
   "metadata": {},
   "source": [
    "## **0.b Chargement du dataset**\n",
    "\n",
    "Si le dataset n'est pas déjà présent localement, on le récupère automatiquement dans sa dernière version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb7d1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download latest version of dataset and store it locally\n",
    "if not os.path.exists(\"data\"):\n",
    "    path = kagglehub.dataset_download(\"paultimothymooney/chest-xray-pneumonia\")\n",
    "\n",
    "    target_dir = \"data\"\n",
    "    os.makedirs(target_dir, exist_ok=True)\n",
    "    shutil.move(path, target_dir)\n",
    "    removable_folder_paths = (\"data/chest_xray/\", \"data/2/chest_xray/chest_xray\", \"data/2/chest_xray/__MACOSX\")\n",
    "    for folder_path in removable_folder_paths:\n",
    "        if os.path.exists(folder_path) and os.path.isdir(folder_path):\n",
    "            shutil.rmtree(folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b49055d",
   "metadata": {},
   "source": [
    "## **1. Compréhension du problème**\n",
    "\n",
    "Nous sommes ici dans le cadre d'un **modèle à application médicale**. Nous devons donc être très attentifs à ce que nous faisons. Plusieurs possibilités différentes peuvent influencer nos choix, selon l'usage de ce modèle :\n",
    "\n",
    "- S'agit-il d'un modèle destiné à détecter la possibilité d'une pneumonie **en amont de l'examen d'un professionnel de santé ?** Dans ce cas, nous voulons privilégier le recall, qui minimise les chances de passer à côté d'une pathologie, quitte a parfois donner de faux positifs.\n",
    "\n",
    "- A l'inverse, s'il s'agit d'un modèle destiné à **valider le diagnostic positif d'un médecin**, on privilégiera alors la précision, puisqu'il s'agira de détecter la maladie à coup sûr et d'éviter les faux positifs.\n",
    "\n",
    "Un modèle plus généraliste pourrait privilégier l'accuracy, mais nous allons ici partir du principe que le modèle est destiné à détecter la maladie **en amont** et déclencher l'appel à l'expertise d'un médecin dès que le moindre doute est soulevé. Nous privilégieront donc le recall, et en valeur secondaire la précision. On veut **un minimum de cas non détectés** et une **qualité de diagnostic positif maximale**, car notre modèle a besoin d'être fiable, de ne rater aucun cas mais également d'être **digne de confiance** (si on détecte 100% des cas mais que la moitié des détections sont des faux positifs, l'outil n'a aucune utilité)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46033f3",
   "metadata": {},
   "source": [
    "## **2. Analyse du dataset**\n",
    "\n",
    "Nous analysons le contenu du dataset, en particulier le format des images et la répartition des classes. Nous utiliserons la fonction **dataset_analysis** définie dans **functions/data/dataset_analysis.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2a66c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1316c7c",
   "metadata": {},
   "source": [
    "On peut voir que les images du dataset peuvent prendre **différents ratio width/height**. Certaines sont en couleur, d'autres non mais cela ne devrait pas poser de souci car elles sont toujours monochrome. Une étude en niveaux de gris serait peut être préférable. Comme les modèles préentrainés attendent du rgb, on peut essayer de les tromper en triplant la valeur d'intensité du greyscale pour le faire passer pour du rgb. Cette approche devra être testée pour en définir l'efficacité. Le dataset ne contient pas d'images erronées. J'observe que les classes sont déséquilibrées avec **seulement un quart des images concernant des poumons sains**, il faudra en tenir compte lors de l'entraînement et trouver des méthodes pour mitiger cela."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8a9f0b",
   "metadata": {},
   "source": [
    "## **3. Preprocessing du dataset**\n",
    "\n",
    "Selon les caractéristiques définies dans **settings > params[\"img_size\"]** et **params[\"rgb\"]**, nous allons transformer les images du dataset pour qu'elles correspondent à ces valeurs après avoir vérifié qu'elles n'y correspondent pas déjà (grâce à un fichier json **data_config**) et les enregistrer dans le dossier **data/processed**. Nous utiliserons pour cela la fonction **prepare_data** définie dans **functions/data/prepare_data.py**. Cette fonction ajoutera des bandes noires sur les côtés de l'image pour obtenir le ratio 1:1 désiré sans en altérer le contenu, la redimensionnera et la convertira en faux rgb (intensité du pxiel dupliqué sur trois channels) si nécessaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8160d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = os.path.join(\"data/processed\", \"data_config.json\")\n",
    "\n",
    "current_config = {\n",
    "    \"rgb\": params[\"rgb\"],\n",
    "    \"img_size\": params[\"img_size\"]\n",
    "}\n",
    "\n",
    "if os.path.exists(config_path):\n",
    "    with open(config_path, \"r\") as f:\n",
    "        previous_config = json.load(f)\n",
    "    if previous_config != current_config:\n",
    "        for folder in folders:\n",
    "            prepare_data(folders[folder][\"input\"], folders[folder][\"output\"])\n",
    "else:\n",
    "    for folder in folders:\n",
    "            prepare_data(folders[folder][\"input\"], folders[folder][\"output\"])\n",
    "\n",
    "with open(config_path, \"w\") as f:\n",
    "        json.dump(current_config, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14f2db7",
   "metadata": {},
   "source": [
    "Nous stockons ensuite les datasets d'entraînement, de test et de validation via la fonction **get_train_test** définie dans **functions/data/get_train_test.py**. \n",
    "\n",
    "Selon la valeur de settings > params[\"equilibrate\"], nous **rééquilibrerons les poids des classes** pour tenter de limiter l'influence du déséquilibre entre les classes lors de l'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94acfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparation des données de travail\n",
    "X_train, y_train = get_train_test(folders[\"train\"][\"output\"])\n",
    "X_test, y_test = get_train_test(folders[\"test\"][\"output\"])\n",
    "X_val, y_val = get_train_test(folders[\"val\"][\"output\"])\n",
    "\n",
    "# Rééquilibrage du dataset\n",
    "class_weight_dict = {0: 1.0, 1: 1.0}\n",
    "if params[\"equilibrate\"]:\n",
    "    class_weights = compute_class_weight(\n",
    "        class_weight='balanced',\n",
    "        classes=np.unique(y_train),\n",
    "        y=y_train\n",
    "    )\n",
    "    class_weight_dict = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462c1411",
   "metadata": {},
   "source": [
    "On affiche un petit echantillonnage de nos dataset pour vérifier que tout est ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b3796f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Echantillonnage pour vérification\n",
    "# Sélectionner les indices des labels\n",
    "indices_label_0 = [i for i, y in enumerate(y_train) if y == 0][:5]\n",
    "indices_label_1 = [i for i, y in enumerate(y_train) if y == 1][:5]\n",
    "\n",
    "# Fusionner les indices sélectionnés\n",
    "selected_indices = indices_label_0 + indices_label_1\n",
    "\n",
    "# Affichage\n",
    "plt.figure(figsize=(15, 3))\n",
    "for idx, i in enumerate(selected_indices):\n",
    "    plt.subplot(1, 10, idx + 1)\n",
    "    plt.imshow(X_train[i], cmap=\"gray\")\n",
    "    plt.title(f\"Label: {'normal' if y_train[i] == 0 else 'pneumonia'}\", fontsize=8)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc35ae0",
   "metadata": {},
   "source": [
    "Nous transformons les images pour les rendre exploitables par les modèles (normalisation des valeurs de pixels, format des réponses attendues..) \n",
    " \n",
    "Selon la valeur de settings > params[\"data_augmentation\"], nous **appliquerons des modifications aléatoires** (rotations, retournements, zoom..) aux images minoritaires pendant l'entrainement pour en aumenter artificellement la diversité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4dd7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "X_train = X_train.astype(\"float32\")\n",
    "X_test = X_test.astype(\"float32\")\n",
    "\n",
    "# Normalisation : on divise les valeurs de pixels par 255 pour les ramener entre 0 et 1\n",
    "X_train /= 255.0\n",
    "X_test /= 255.0\n",
    "\n",
    "#Transform y_train, y_test to the shape expected by the model\n",
    "y_train = to_categorical(y_train, num_classes=2)\n",
    "y_test = to_categorical(y_test, num_classes=2)\n",
    "y_val = to_categorical(y_val, num_classes=2)\n",
    "\n",
    "if params[\"data_augmentation\"]:\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=10,\n",
    "        horizontal_flip=True,\n",
    "        zoom_range=0.1,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "    )\n",
    "\n",
    "    datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5a08f4",
   "metadata": {},
   "source": [
    "## **4. Création du modèle**\n",
    "\n",
    "Nous créons le modèle grâce à une fonction **initialize_model** qui prend en compte les paramètres définis dans **settings > params** et les couches supplémentaires définies dans **settings > added_layers**. Celà nous permet de **facilement tester de nombreux paramètres/modèles différents sans devoir toucher au code**, et de **tout logger facilement dans MLFlow** par la suite pour comparaison ultérieure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3bc5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création du modèle\n",
    "model = initialize_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6ddd21",
   "metadata": {},
   "source": [
    "## **5. Entraînement du modèle**\n",
    "\n",
    "Nous entrainons le modèle sur notre dataset d'entraînement, et surveillerons ses résultats à chaque epoch pour vérifier qu'il évolue dans le bon sens et ne se surentraîne pas.\n",
    "\n",
    "Pour ce cas précis nous surveillons son évolution à partir du dataset de test, car les métriques fournies par le dataset d'évaluation sont trop éloignées des résultats finaux et ne nous offrent pas un bon indicateur de l'évolution de la performance du modèle. En général il aurait fallu ici utiliser le dataset de validation, plus léger pour accélérer l'entraînement.\n",
    "\n",
    "Si **settings > params[\"data_augmentation\"] == True**, on utilise ici les techniques de rotation, zoom,.. définies précédemment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fee7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrainement du modèle\n",
    "if params[\"data_augmentation\"]:\n",
    "    model_info = model.fit(\n",
    "        datagen.flow(X_train, y_train, batch_size=params[\"batch_size\"]),\n",
    "        epochs=params[\"epochs\"],\n",
    "        validation_data=(X_test, y_test),\n",
    "        class_weight=class_weight_dict\n",
    "    )\n",
    "else:\n",
    "    model_info = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=params[\"epochs\"],\n",
    "        batch_size=params[\"batch_size\"],\n",
    "        validation_data=(X_test, y_test),\n",
    "        class_weight=class_weight_dict\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1e2b58",
   "metadata": {},
   "source": [
    "## **6. Mise en place d'un suivi des tests**  \n",
    "\n",
    "Nous affichons la matrice de confusion de notre modèle, et l'enregistrons en tant qu'image pour pouvoir la logger plus tard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129c9e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice de confusion\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "\n",
    "labels = [\"Normal\", \"Pneumonia\"]\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=labels)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "\n",
    "disp.plot(cmap='GnBu', ax=ax) \n",
    "plt.title(\"Confusion matrix\")\n",
    "img_path = \"confusion_matrix.png\"\n",
    "plt.savefig(img_path)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353d84eb",
   "metadata": {},
   "source": [
    "Grâce à MLFlow, nous enregistrons les résultats de nos tests (paramètres et résultats) afin de **facilement comparer nos modèles/paramètres d'entraïnement**.\n",
    "\n",
    "Nous loggons :\n",
    "- Le lien du dataset\n",
    "- Les paramètres\n",
    "- Les métriques finaux\n",
    "- Les métriques de suivi durant l'entraînement\n",
    "- La matrice de confusion (sous forme d'artifact)\n",
    "- Le modèle\n",
    "- Les poids du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae9bb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log results into MLFlow\n",
    "results = model.evaluate(X_test, y_test, return_dict=True)\n",
    "\n",
    "mlflow.set_tracking_uri(os.getenv(\"MLFLOW_TRACKING_URI\"))\n",
    "os.environ[\"MLFLOW_TRACKING_USERNAME\"] = os.getenv(\"MLFLOW_TRACKING_USERNAME\")\n",
    "os.environ[\"MLFLOW_TRACKING_PASSWORD\"] = os.getenv(\"MLFLOW_TRACKING_PASSWORD\")\n",
    "    \n",
    "experiment = mlflow.set_experiment(experiment_name=experiment_name)\n",
    "run_name = get_run_name(experiment, params[\"model\"])\n",
    "\n",
    "weights_path = \"model.weights.h5\"\n",
    "model.save_weights(weights_path)\n",
    "\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    run_id = run.info.run_id\n",
    "\n",
    "    # Log dataset\n",
    "    mlflow.log_param(\"dataset_url\", \"https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia\")\n",
    "    mlflow.set_tag(\"dataset\", \"chest-xray-pneumonia\")\n",
    "    mlflow.set_tag(\"testing_cycle\", testing_cycle)\n",
    "\n",
    "    # Log parameters\n",
    "    mlflow.log_params(params)\n",
    "    for i, added_layer in enumerate(added_layers):\n",
    "        mlflow.log_params({\n",
    "            f\"added_layer_{i}\": added_layer\n",
    "        })\n",
    "    # Log training metrics\n",
    "    for epoch in range(len(model_info.history['loss'])):\n",
    "        for metric_name, values in model_info.history.items():\n",
    "            mlflow.log_metric(f\"training {metric_name}\", values[epoch], step=epoch)\n",
    "    # Log final metrics\n",
    "    mlflow.log_metrics(\n",
    "        results\n",
    "    )\n",
    "    # Log confusion matrix\n",
    "    mlflow.log_artifact(img_path, artifact_path=\"confusion_matrix\")\n",
    "    # Log model\n",
    "    mlflow.log_artifact(weights_path)\n",
    "    mlflow.tensorflow.log_model(\n",
    "            model=model,\n",
    "            artifact_path=model_name,\n",
    "            input_example=X_test[:5],\n",
    "            signature = infer_signature(X_test, model.predict(X_test))\n",
    "        )\n",
    "\n",
    "    model_uri = f\"runs:/{run_id}/{model_name}\"\n",
    "    mlflow.register_model(model_uri=model_uri, name=model_name)\n",
    "\n",
    "os.remove(\"model.weights.h5\")\n",
    "os.remove(\"confusion_matrix.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b20d70",
   "metadata": {},
   "source": [
    "## **7. Choix du modèle**  \n",
    "\n",
    "Après avoir testé différents modèles préentrainés potentiellement intéressants, nous les comparons grâce aux métriques enregistrés dans MLFlow afin de choisir notre modèle de travail final. Comme vu auparavant, nous allons nous intéresser à recall_pneumonia, precision_pneumonia, avec en soutien la courbe auc qui représente la fiabilité générale de notre modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6221ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(os.getenv(\"MLFLOW_TRACKING_URI\"))\n",
    "os.environ[\"MLFLOW_TRACKING_USERNAME\"] = os.getenv(\"MLFLOW_TRACKING_USERNAME\")\n",
    "os.environ[\"MLFLOW_TRACKING_PASSWORD\"] = os.getenv(\"MLFLOW_TRACKING_PASSWORD\")\n",
    "\n",
    "experiment_id = \"1\"\n",
    "client = MlflowClient()\n",
    "\n",
    "# On récupère les runs taggés comme candidats pour les comparer\n",
    "runs = client.search_runs(\n",
    "    experiment_ids=[experiment_id],\n",
    "    filter_string=\"tags.candidate = 'true'\",\n",
    "    order_by=[\"metrics.step ASC\"]\n",
    ")\n",
    "\n",
    "show_metrics(runs, client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fb1ceb",
   "metadata": {},
   "source": [
    "On affiche également leurs **matrices de confusion** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2534f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_matrix(runs, client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281e0cc9",
   "metadata": {},
   "source": [
    "Après analyse de toutes ces métriques, nous choisirons de continuer avec le modèle **MobileNetV2**, qui combine **très bon recall**, **très bonne précision** et **excellente fiabilité**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4821ee",
   "metadata": {},
   "source": [
    "## **8. Affiner notre modèle**  \n",
    "\n",
    "Une fois notre modèle final sélectioné, nous jouons avec ses paramètres afin de chercher les **meilleures performances possibles pour le cas étudié**. On changera les **couches de sortie**, on tentera de **dégeler certaines couches du modèle préentrainé**, on modifiera la batch_size, le nombre d'epoch.. Pour voir quels paramètres ont un effet positif sur ses performances. Tout cela sera loggé dans MLFlow pour analyse comparative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2598654e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(os.getenv(\"MLFLOW_TRACKING_URI\"))\n",
    "os.environ[\"MLFLOW_TRACKING_USERNAME\"] = os.getenv(\"MLFLOW_TRACKING_USERNAME\")\n",
    "os.environ[\"MLFLOW_TRACKING_PASSWORD\"] = os.getenv(\"MLFLOW_TRACKING_PASSWORD\")\n",
    "\n",
    "experiment_id = \"1\"\n",
    "client = MlflowClient()\n",
    "\n",
    "# On récupère les runs challenger pour les comparer\n",
    "runs_1 = client.search_runs(\n",
    "    experiment_ids=[experiment_id],\n",
    "    filter_string=\"tags.challenger = 'true'\",\n",
    "    order_by=[\"metrics.step ASC\"]\n",
    ")\n",
    "\n",
    "# On récupère le run champion\n",
    "runs_2 = client.search_runs(\n",
    "    experiment_ids=[experiment_id],\n",
    "    filter_string=\"tags.champion = 'true'\",\n",
    "    order_by=[\"metrics.step ASC\"]\n",
    ")\n",
    "\n",
    "runs = runs_1 + runs_2\n",
    "\n",
    "show_metrics(runs, client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a44e265",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_matrix(runs, client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef67c14a",
   "metadata": {},
   "source": [
    "Affichons également les paramètres de ces runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d25d0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_parameters(runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572fcdbf",
   "metadata": {},
   "source": [
    "## **9. Résultats finaux**  \n",
    "\n",
    "Après analyse de ces métriques, le modèle **MobileNetV2#1** reste le meilleur de par sa précision élevée. C'est donc ce modèle que nous allons proposer en démonstration :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965b8d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(os.getenv(\"MLFLOW_TRACKING_URI\"))\n",
    "os.environ[\"MLFLOW_TRACKING_USERNAME\"] = os.getenv(\"MLFLOW_TRACKING_USERNAME\")\n",
    "os.environ[\"MLFLOW_TRACKING_PASSWORD\"] = os.getenv(\"MLFLOW_TRACKING_PASSWORD\")\n",
    "\n",
    "model_name = \"Transfer Learning - MobileNetV2\"\n",
    "model_version = 1\n",
    "\n",
    "model_uri = f\"models:/{model_name}/{model_version}\"\n",
    "\n",
    "loaded_model = mlflow.tensorflow.load_model(model_uri)\n",
    "\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "show_predictions(X_val, y_pred, y_true=y_val, class_names=[\"normal\", \"malade\"], n_images=15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
